{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.genmod.families.links import Logit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle, os\n",
    "\n",
    "from scipy.sparse import load_npz, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, brier_score_loss\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def make_splits(df, n_splits, test_size=0.1):\n",
    "  unq_ids = df[\"user_id\"].unique()\n",
    "  splitter = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0)\n",
    "  return list(splitter.split(unq_ids))\n",
    "\n",
    "\n",
    "def get_file_path(ds, generation_type, model_type, fold_num):\n",
    "  dir_path = f\"./simulation-result/{ds}/{model_type}\"\n",
    "  os.makedirs(dir_path, exist_ok=True)\n",
    "  path = f\"{dir_path}/{ds}_simulated_{generation_type}_model_{model_type}_{fold_num}\"\n",
    "  return f\"{path}.sav\", f\"{path}_test.csv\"\n",
    "\n",
    "\n",
    "def run_lr(df, X_fp, splits, ds, generation_model, simulated_model):\n",
    "  X = csr_matrix(load_npz(X_fp))\n",
    "  for idx, (users_train, users_test) in enumerate(splits):\n",
    "    user_ids = X[:, 0].toarray().flatten()\n",
    "    train = X[np.where(np.isin(user_ids, users_train))]\n",
    "    test = X[np.where(np.isin(user_ids, users_test))]\n",
    "\n",
    "    test_df = df[df[\"user_id\"].isin(users_test)]\n",
    "\n",
    "    X_train, y_train = train[:, 5:], train[:, 3].toarray().flatten()\n",
    "    X_test, y_test = test[:, 5:], test[:, 3].toarray().flatten()\n",
    "\n",
    "    # print(test_df.tail(10))\n",
    "    # print('====')\n",
    "    # print(X_test[-10:])\n",
    "    # print('+++++')\n",
    "\n",
    "\n",
    "    model = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    test_df['y_pred'] = y_pred\n",
    "    test_df['y_true'] = y_test\n",
    "\n",
    "    # Save model\n",
    "    model_path, csv_path = get_file_path(ds, generation_model, simulated_model, idx)\n",
    "    pickle.dump(model, open(model_path, 'wb'))\n",
    "    test_df.to_csv(csv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "  ''' \n",
    "  In the folder:\n",
    "  - algebra05\n",
    "    - bestlr\n",
    "      - algebra05_simulated_bestlr_model_bestlr_0.sav\n",
    "      - algebra05_simulated_bestlr_model_dkt_0.sav\n",
    "      - algebra05_simulated_bestlr_model_pfa_0.sav\n",
    "      - algebra05_simulated_bestlr_model_bestlr_1.sav\n",
    "      - algebra05_simulated_bestlr_model_dkt_1.sav\n",
    "      - algebra05_simulated_bestlr_model_pfa_1.sav\n",
    "      - algebra05_simulated_bestlr_model_bestlr_test_0.csv\n",
    "      - algebra05_simulated_bestlr_model_dkt_test_0.csv\n",
    "  '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from model_dkt2 import DKT2\n",
    "from train_dkt2 import get_data, prepare_batches, compute_auc, compute_loss, train\n",
    "def run_dkt(df, splits, ds, generation_model, simulated_model):\n",
    "  for idx, (users_train, users_test) in enumerate(splits):\n",
    "    test_df = df[df[\"user_id\"].isin(users_test)]\n",
    "    train_df = df[df[\"user_id\"].isin(users_train)]\n",
    "\n",
    "    model = train_dkt(train_df, test_df)\n",
    "    preds = eval_dkt(model, test_df)\n",
    "    test_df['y_pred'] = preds\n",
    "\n",
    "    # Save model\n",
    "    model_path, csv_path = get_file_path(ds, generation_model, simulated_model, idx)\n",
    "    pickle.dump(model, open(model_path, 'wb'))\n",
    "    test_df.to_csv(csv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "def train_dkt(train_df, test_df, hid_size=200, embed_size=200, \n",
    "              num_hid_layers=1, drop_prob=.5, _batch_size=64,\n",
    "              log_dir='runs/dkt', savedir='save/dkt',\n",
    "              lr=1e-2, num_epochs=100, seed=0):\n",
    "  set_random_seeds(seed)\n",
    "  train_data, val_data = get_data(train_df, train_split=0.8)\n",
    "\n",
    "  max_item = max(int(train_df[\"item_id\"].max()), int(test_df[\"item_id\"].max()))\n",
    "  max_skill = max(int(train_df[\"skill_id\"].max()), int(test_df[\"skill_id\"].max()))\n",
    "\n",
    "  model = DKT2(max_item, max_skill, hid_size,\n",
    "                embed_size, num_hid_layers, drop_prob).cuda()\n",
    "  optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  # Reduce batch size until it fits on GPU\n",
    "  while True:\n",
    "    try:\n",
    "      # Train\n",
    "      param_str = f\"{dataset}\"\n",
    "      logger = Logger(os.path.join(log_dir, param_str))\n",
    "      saver = Saver(savedir, param_str)\n",
    "      train(train_data, val_data, model, optimizer, logger, saver, num_epochs, batch_size)\n",
    "      break\n",
    "    except RuntimeError as e:\n",
    "      print(e)\n",
    "      batch_size = batch_size // 2\n",
    "      print(f'Batch does not fit on gpu, reducing size to {batch_size}')\n",
    "  \n",
    "  logger.close()\n",
    "  return model\n",
    "\n",
    "def eval_dkt(model, test_df, savedir='save/dkt'):\n",
    "    if(isinstance(model, str)):\n",
    "        saver = Saver(savedir, model)\n",
    "        model = saver.load()\n",
    "    test_data, _ = get_data(test_df, train_split=1.0, randomize=False)\n",
    "    test_batches = prepare_batches(test_data, batch_size, randomize=False)\n",
    "    test_preds = np.empty(0)\n",
    "    test_skill_preds = np.empty(0)\n",
    "\n",
    "    # Predict on test set\n",
    "    model.eval()\n",
    "    for item_inputs, skill_inputs, label_inputs, item_ids, skill_ids, labels in test_batches:\n",
    "        with torch.no_grad():\n",
    "            item_inputs = item_inputs.cuda()\n",
    "            skill_inputs = skill_inputs.cuda()\n",
    "            label_inputs = label_inputs.cuda()\n",
    "            item_ids = item_ids.cuda()\n",
    "            skill_ids = skill_ids.cuda()\n",
    "\n",
    "            # Make the per-item prediction\n",
    "            preds = model(item_inputs, skill_inputs, label_inputs, item_ids, skill_ids)\n",
    "            preds = torch.sigmoid(preds[labels >= 0]).cpu().numpy()\n",
    "            test_preds = np.concatenate([test_preds, preds])\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics', 'assistments12']\n",
    "datasets = ['algebra05']\n",
    "n_folds = 1\n",
    "for d in datasets:\n",
    "  # for simulated_model in ['bestlr', 'pfa', 'dkt']:\n",
    "  for simulated_model in ['bestlr']:\n",
    "    dir_path = f'./simulation/{d}/{simulated_model}'\n",
    "    dataset_fp = f'{dir_path}/simulated-{simulated_model}.csv'\n",
    "    X_pfa_fp = f'{dir_path}/X-sscwa.npz'\n",
    "    X_bestlr_fp = f'{dir_path}/X-isicsctcwa.npz'\n",
    "\n",
    "    df = pd.read_csv(dataset_fp, sep=\"\\t\")\n",
    "    splits = make_splits(df, n_folds)\n",
    "    run_lr(df, X_bestlr_fp, splits, d, 'bestlr', simulated_model)\n",
    "    run_lr(df, X_pfa_fp, splits, d, 'pfa', simulated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
