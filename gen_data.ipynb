{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.genmod.families.links import Logit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pymer4.models import Lmer\n",
    "from pymer4.io import save_model, load_model\n",
    "\n",
    "\n",
    "datasets = ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics'] # 'assistments12'\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "def loading(iters):\n",
    "    return tqdm(iters, desc=\"Running ...\", ascii=False, ncols=75)\n",
    "\n",
    "def inv_logit(z):\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def calc_pfa_prob(s_opp, f_opp, s_slope, f_slope, stu_intercept, kc_intercept, ovr_intercept):\n",
    "  z = (s_slope * s_opp) + (f_slope * f_opp) + stu_intercept + kc_intercept + ovr_intercept\n",
    "  return inv_logit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN MODEL ###\n",
    "\n",
    "formulas = {\n",
    "  \"AFM\": \"correct ~ opp + (opp|skill_id) + (1|user_id)\",\n",
    "  \"PFA\": \"correct ~ s_opp + f_opp + (s_opp|skill_id) + (f_opp|skill_id) + (1|user_id)\",\n",
    "}\n",
    "\n",
    "# model.fit(control=\"optimizer='Nelder_Mead', optCtrl = list(FtolAbs=1e-8, XtolRel=1e-8)\")\n",
    "def run(df, model_type=\"PFA\"):\n",
    "  model = Lmer(formulas[model_type], data=df, family=\"binomial\")\n",
    "  model.fit(control=\"optimizer='bobyqa', optCtrl=list(maxfun=2e5)\", summarize=False)\n",
    "\n",
    "  print(f\"{model_type}: AIC: {model.AIC}, BIC: {model.BIC}, LogLik: {model.logLike}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model failed to converge with max|grad| = 0.00384345 (tol = 0.002, component 1) \n",
      "\n",
      "PFA: AIC: 556648.672887014, BIC: 556761.8354476446, LogLik: -278314.336443507\n"
     ]
    }
   ],
   "source": [
    "def prepare_df(fp):\n",
    "  df = pd.read_csv(fp, delimiter='\\t')\n",
    "  df['opp'] = df.groupby(['user_id', 'skill_id']).cumcount()\n",
    "  df['s_opp'] = ((df['correct'] == 1).groupby([df['user_id'], df['skill_id']]).cumsum()).fillna(0)\n",
    "  df['f_opp'] = ((df['correct'] == 0).groupby([df['user_id'], df['skill_id']]).cumsum()).fillna(0)\n",
    "  df.loc[df['correct'] == 1, 's_opp'] = df['s_opp'] - 1\n",
    "  df.loc[df['correct'] == 0, 'f_opp'] = df['f_opp'] - 1\n",
    "  return df\n",
    "\n",
    "### Finished Running ###\n",
    " \n",
    "# assistment09_df = prepare_df('data/assistments09/preprocessed_data.csv')\n",
    "# assistment09_model = run(assistment09_df)\n",
    "\n",
    "# assistment15_df = prepare_df('data/assistments15/preprocessed_data.csv')\n",
    "# assistment15_model = run(assistment15_df)\n",
    "\n",
    "# spanish_df = prepare_df('data/spanish/preprocessed_data.csv')\n",
    "# spanish_model = run(spanish_df)\n",
    "\n",
    "# assistment17_df = prepare_df('data/assistments17/preprocessed_data.csv')\n",
    "# assistment17_model = run(assistment17_df)\n",
    "\n",
    "# statics_df = prepare_df('data/statics/preprocessed_data.csv')\n",
    "# statics_model = run(statics_df)\n",
    "\n",
    "# bridge_df = prepare_df('data/bridge_algebra06/preprocessed_data.csv')\n",
    "# bridge_model = run(bridge_df)\n",
    "\n",
    "algebra_df = prepare_df('data/algebra05/preprocessed_data.csv')\n",
    "algebra_model = run(algebra_df)\n",
    "\n",
    "### To Run ###\n",
    "\n",
    "# assistment12_df = prepare_df('data/assistments12/preprocessed_data.csv')\n",
    "# assistment12_model = run(assistment12_df)\n",
    "\n",
    "### Save Models and Data ###\n",
    "\n",
    "# save_model(assistment09_model, './simulation/models/assistment09-model.joblib')\n",
    "# save_model(assistment15_model, './simulation/models/assistment15-model.joblib')\n",
    "# save_model(assistment17_model, './simulation/models/assistment17-model.joblib')\n",
    "# save_model(spanish_model, './simulation/models/spanish-model.joblib')\n",
    "# save_model(statics_model, './simulation/models/statics-model.joblib')\n",
    "# save_model(bridge_model, './simulation/models/bridge-model.joblib')\n",
    "# save_model(algebra_model, './simulation/models/algebra05.joblib')\n",
    "\n",
    "# assistment09_df.to_csv('./simulation/extended-data/assistment09.csv')\n",
    "# assistment15_df.to_csv('./simulation/extended-data/assistment15.csv')\n",
    "# assistment17_df.to_csv('./simulation/extended-data/assistment17.csv')\n",
    "# spanish_df.to_csv('./simulation/extended-data/spanish.csv')\n",
    "# statics_df.to_csv('./simulation/extended-data/statics.csv')\n",
    "# bridge_df.to_csv('./simulation/extended-data/bridge.csv')\n",
    "# algebra_df.to_csv('./simulation/extended-data/algebra05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_stu_and_kc_params_from_model_pfa(model, ds):\n",
    "  # if ds in reverse:\n",
    "  #   kc_params, stu_params = model.ranef\n",
    "  # else:\n",
    "  #   stu_params, kc_params = model.ranef\n",
    "\n",
    "  stu_params, kc_params = model.ranef\n",
    "  fixef = model.coefs.Estimate\n",
    "\n",
    "  overall_int = fixef['(Intercept)']\n",
    "  overall_s_slope = fixef['s_opp']\n",
    "  overall_f_slope = fixef['f_opp']\n",
    "\n",
    "  overall = pd.DataFrame([[overall_int, overall_s_slope, overall_f_slope, ds]], columns=['Intercept', 'S_Slope', 'F_Slope', 'Dataset'])\n",
    "\n",
    "  stu_params['Dataset'] = ds\n",
    "  stu_params.reset_index(inplace=True)\n",
    "  stu_params = stu_params.rename(columns={\n",
    "    \"index\": \"Student\",\n",
    "    \"X.Intercept.\": \"Intercept\"\n",
    "  })\n",
    "\n",
    "  kc_params['Dataset'] = ds\n",
    "  kc_params.reset_index(inplace=True)\n",
    "  kc_params = kc_params.rename(columns={\n",
    "    \"index\": \"KC\",\n",
    "    \"X.Intercept.\": \"PFA_S_Intercept\",\n",
    "    \"X.Intercept..1\": \"PFA_F_Intercept\",\n",
    "    \"s_opp\": \"S_Slope/KC\",\n",
    "    \"f_opp\": \"F_Slope/KC\",\n",
    "  })\n",
    "\n",
    "  return stu_params, kc_params, overall\n",
    "\n",
    "\n",
    "def create_params_files():\n",
    "  pfa_stu_params, pfa_kc_params, pfa_overall_params= [], [], []\n",
    "  for ds in datasets:\n",
    "    print(f\"Running: {ds}\")\n",
    "    pfa_model = load_model(f'./simulation/models/{ds}-model.joblib')\n",
    "    stu_params, kc_params, overall_params  = _get_stu_and_kc_params_from_model_pfa(pfa_model, ds)\n",
    "    pfa_stu_params.append(stu_params)\n",
    "    pfa_kc_params.append(kc_params)\n",
    "    pfa_overall_params.append(overall_params)\n",
    "\n",
    "  # - start - Run these to generate new model param files\n",
    "\n",
    "  pfa_stu_params_concat = pd.concat(pfa_stu_params, axis=0).reset_index(drop=True)\n",
    "  pfa_kc_params_concat = pd.concat(pfa_kc_params, axis=0).reset_index(drop=True)\n",
    "  pfa_overall_params_concat = pd.concat(pfa_overall_params, axis=0).reset_index(drop=True)\n",
    "\n",
    "  pfa_stu_params_concat.to_csv(\"./simulation/model-values/pfa_std_params.csv\", sep=\",\", index=False)\n",
    "  pfa_kc_params_concat.to_csv(\"./simulation/model-values/pfa_kc_params.csv\", sep=\",\", index=False) \n",
    "  pfa_overall_params_concat.to_csv(\"./simulation/model-values/pfa_overall_params.csv\", sep=\",\", index=False) \n",
    "\n",
    "# create_params_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET MODEL VALUES FROM MODEL VALUE CSV. ###\n",
    "\n",
    "PFA_STU_FP = \"./simulation/model-values/pfa_std_params.csv\"\n",
    "PFA_KC_FP = \"./simulation//model-values/pfa_kc_params.csv\"\n",
    "PFA_OVERALL_FP = \"./simulation/model-values/pfa_overall_params.csv\"\n",
    "\n",
    "def _get_kc_values(fp, get_value_func):\n",
    "  df = pd.read_csv(fp, delimiter=',')\n",
    "  kc_values_by_ds = {}\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "    ds = row['Dataset']\n",
    "    if ds not in kc_values_by_ds:\n",
    "      kc_values_by_ds[ds] = {}\n",
    "    \n",
    "    kc_name = row['KC']\n",
    "    if kc_name in kc_values_by_ds[ds]:\n",
    "      print(f\"[ERROR] Duplicated KC: {kc_name}\")\n",
    "    kc_values_by_ds[ds][row['KC']] = get_value_func(row)\n",
    "  return kc_values_by_ds\n",
    "\n",
    "def _get_student_values(fp):\n",
    "  df = pd.read_csv(fp, delimiter=',')\n",
    "  stu_intercepts = {}\n",
    "  for _, row in df.iterrows():\n",
    "    ds = row['Dataset']\n",
    "    if ds not in stu_intercepts:\n",
    "      stu_intercepts[ds] = {}\n",
    "    stu_intercepts[ds][row['Student']] = row['Intercept']\n",
    "  return stu_intercepts\n",
    "\n",
    "def get_pfa_kc_values():\n",
    "  def _get_pfa(row):\n",
    "    return {\n",
    "      'intercept': row['PFA_S_Intercept'] + row['PFA_F_Intercept'],\n",
    "      's_slope_kc': row['S_Slope/KC'],\n",
    "      'f_slope_kc': row['F_Slope/KC']\n",
    "    }\n",
    "  return _get_kc_values(PFA_KC_FP, _get_pfa)\n",
    "\n",
    "def get_pfa_student_values(): return _get_student_values(PFA_STU_FP)\n",
    "\n",
    "def _get_overall_values(fp, get_value_func):\n",
    "  df = pd.read_csv(fp, delimiter=',')\n",
    "  overall_params = {}\n",
    "  for _, row in df.iterrows():\n",
    "    ds = row['Dataset']\n",
    "    if ds not in overall_params:\n",
    "      overall_params[ds] = {}\n",
    "\n",
    "    overall_params[ds] = get_value_func(row)\n",
    "  return overall_params\n",
    "\n",
    "def get_pfa_overall_values():\n",
    "  def _get_pfa(row):\n",
    "    return {\n",
    "      'intercept': row['Intercept'],\n",
    "      's_slope': row['S_Slope'],\n",
    "      'f_slope': row['F_Slope'],\n",
    "    }\n",
    "  return _get_overall_values(PFA_OVERALL_FP, _get_pfa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_values_by_ds = get_pfa_kc_values()\n",
    "stu_values_by_ds = get_pfa_student_values()\n",
    "ovr_values_by_ds = get_pfa_overall_values()\n",
    "\n",
    "def simulate(fp, ds):\n",
    "  kc_values = kc_values_by_ds[ds]\n",
    "  stu_intercepts = stu_values_by_ds[ds] \n",
    "  ovr_params = ovr_values_by_ds[ds]\n",
    "\n",
    "  columns = ['user_id', 'item_id', 'timestamp', 'correct', 'skill_id', 's_opp', 'f_opp', 'prob']\n",
    "  opps = {}\n",
    "  rows = []\n",
    "  df = pd.read_csv(fp, delimiter='\\t')\n",
    "  for _, row in loading(list(df.iterrows())):\n",
    "    user_id = row['user_id']\n",
    "    skill_id = row['skill_id']\n",
    "\n",
    "    kc_value = kc_values[skill_id]\n",
    "    stu_intercept = stu_intercepts[user_id]\n",
    "\n",
    "    if user_id not in opps:\n",
    "      opps[user_id] = {}\n",
    "    if skill_id not in opps[user_id]:\n",
    "      opps[user_id][skill_id] = {'s': 0, 'f': 0}\n",
    "\n",
    "    prior_s = opps[user_id][skill_id]['s']\n",
    "    prior_f = opps[user_id][skill_id]['f']\n",
    "\n",
    "    dat = pd.DataFrame([[user_id, row['item_id'], row['timestamp'], None, skill_id, prior_s, prior_f, None]], columns=columns)\n",
    "\n",
    "    print(dat)\n",
    "    print(ovr_params)\n",
    "    print(kc_value)\n",
    "    print(stu_intercept)\n",
    "    prob = calc_pfa_prob(prior_s, prior_f, \n",
    "                        ovr_params['s_slope'] + kc_value['s_slope_kc'], \n",
    "                        ovr_params['f_slope'] + kc_value['f_slope_kc'],\n",
    "                        kc_value['intercept'], stu_intercept, ovr_params['intercept'])\n",
    "    correct = np.random.choice([1, 0], p=[prob, 1-prob])\n",
    "\n",
    "    # prob = model.predict(dat)[0]\n",
    "    # correct = np.random.choice([1, 0], p=[prob, 1-prob])\n",
    "    opps[user_id][skill_id]['s' if correct == 'correct' else 'f'] += 1\n",
    "\n",
    "    dat['prob'] = prob\n",
    "    dat['correct'] = correct\n",
    "    rows.append(dat)\n",
    "    \n",
    "  final = pd.concat(rows, axis=0)\n",
    "  final.to_csv(f'./simulation/simulated-data/{ds}.csv', index=False, sep='\\t')\n",
    "\n",
    "# simulate('data/statics/preprocessed_data.csv', 'statics')\n",
    "simulate('data/spanish/preprocessed_data.csv', 'spanish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_values_by_ds['spanish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excludes = ['statics']\n",
    "\n",
    "for ds in datasets:\n",
    "  if ds in excludes:\n",
    "    continue\n",
    "  simulate(f'data/{ds}/preprocessed_data.csv', ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algebra05', 'assistments09', 'assistments12', 'assistments15', 'assistments17', 'assistments17_first_attempt', 'assistments17_single_attempt', 'bridge_algebra06', 'spanish', 'statics']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"data\"\n",
    "folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "\n",
    "print(folders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
