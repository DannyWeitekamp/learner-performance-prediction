{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.genmod.families.links import Logit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from scipy.sparse import load_npz, csr_matrix\n",
    "\n",
    "datasets = ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics', 'assistments12']\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "def loading(iters):\n",
    "    return tqdm(iters, desc=\"Running ...\", ascii=False, ncols=75)\n",
    "\n",
    "def inv_logit(z):\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def calc_pfa_prob(s_opp, f_opp, s_slope, f_slope, stu_intercept, kc_intercept, ovr_intercept):\n",
    "  z = (s_slope * s_opp) + (f_slope * f_opp) + stu_intercept + kc_intercept + ovr_intercept\n",
    "  return inv_logit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encode_fast as ef\n",
    "from importlib import reload\n",
    "reload(ef)\n",
    "\n",
    "# ACTIVE_FEATURES = ['i', 's', 'ic', 'sc', 'tc', 'w', 'a']\n",
    "ACTIVE_FEATURES = ['s', 'sc', 'w', 'a']\n",
    "def simulate_bestlr(ds):\n",
    "  csv_fp = f'./data/real/{ds}/preprocessed_data.csv'\n",
    "  model_fp = f'./data/real/{ds}/real-pfa-model.sav'\n",
    "  q_fp = f'./data/real/{ds}/q_mat.npz'\n",
    "\n",
    "  columns = ['user_id', 'item_id', 'timestamp', 'correct', 'skill_id', 'prob']\n",
    "  opps = {}\n",
    "  rows = []\n",
    "  df = pd.read_csv(csv_fp, delimiter='\\t')\n",
    "  Q_mat = load_npz(q_fp).toarray()\n",
    "  \n",
    "  num_items, num_skills = Q_mat.shape\n",
    "  model = pickle.load(open(model_fp, 'rb'))\n",
    "\n",
    "  for user_id, group in df.groupby('user_id'):\n",
    "    if user_id not in opps:\n",
    "      opps[user_id] = {\n",
    "        'items': {}, \n",
    "        'skills': {\n",
    "          'count': np.zeros(num_skills),\n",
    "          'success': np.zeros(num_skills),\n",
    "        },\n",
    "        'total': { 'count': 0, 'success': 0}\n",
    "        }\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "      skill_id = row['skill_id']\n",
    "      item_id = row['item_id']\n",
    "      if item_id not in opps[user_id]['items']:\n",
    "        opps[user_id]['items'][item_id] = { 'count': 0, 'success': 0 }\n",
    "\n",
    "      skills = Q_mat[row['item_id']].copy()\n",
    "      opps[user_id]\n",
    "        \n",
    "      skill_ids = np.nonzero(skills)[0]\n",
    "\n",
    "      # X = ef.single_to_sparse(group[idx], Q_mat, ACTIVE_FEATURES)\n",
    "      X = ef.single_to_sparse(df, Q_mat, user_id, \n",
    "                              item_id, \n",
    "                              opps[user_id]['items'][item_id]['count'],\n",
    "                              opps[user_id]['items'][item_id]['success'],\n",
    "                              skills, opps[user_id]['skills']['count'],\n",
    "                              opps[user_id]['skills']['success'],\n",
    "                              opps[user_id]['total']['count'], \n",
    "                              opps[user_id]['total']['success'], \n",
    "                              ACTIVE_FEATURES)\n",
    "\n",
    "      prob = model.predict_proba(X)[0][1]\n",
    "      correct = np.random.choice([1, 0], p=[prob, 1-prob])\n",
    "      # correct = row['correct']\n",
    "\n",
    "      opps[user_id]['items'][item_id]['count'] += 1\n",
    "      opps[user_id]['items'][item_id]['success'] += 1 if correct == 1 else 0\n",
    "      opps[user_id]['total']['count'] += 1\n",
    "      opps[user_id]['total']['success'] += 1 if correct == 1 else 0\n",
    "\n",
    "      opps[user_id]['skills']['count'] += skills\n",
    "      if True or correct == 1:\n",
    "        skill_ids = np.nonzero(skills)[0]\n",
    "        l = len(skill_ids)\n",
    "        opps[user_id]['skills']['success'] += csr_matrix((np.ones(l), (np.zeros(l), skill_ids)), shape=(1, num_skills)).toarray().reshape(-1)\n",
    "\n",
    "      dat = [user_id, row['item_id'], row['timestamp'], correct, skill_id, prob]\n",
    "      rows.append(dat)\n",
    "    \n",
    "  final = pd.DataFrame(rows, columns=columns)\n",
    "  final.to_csv(f'./simulation/simulated-data-pfa/{ds}/{ds}.csv', index=False, sep='\\t')\n",
    "  # final.to_csv(f'./simulation/simulated-data/{ds}/foo.csv', index=False, sep='\\t')\n",
    "\n",
    "# simulate_bestlr('statics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algebra05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ...: 100%|███████████████████████| 567/567 [37:30<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistments09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ...: 100%|█████████████████████| 3114/3114 [18:04<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import encode_fast as ef\n",
    "# for f in os.listdir('./data'):\n",
    "for f in ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics', 'assistments12']:\n",
    "  print(f)\n",
    "  simulate_bestlr(f)\n",
    "\n",
    "# from scipy.sparse import load_npz, csr_matrix\n",
    "# data_fp = \"./data/statics/X-isicsctcwa.npz\"\n",
    "# X = csr_matrix(load_npz(data_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algebra05: There is != 1 - count=59532\n",
      "assistments09: There is != 1 - count=3016\n",
      "assistments15: Ok!\n",
      "assistments17: There is != 1 - count=697\n",
      "bridge_algebra06: There is != 1 - count=1626\n",
      "spanish: Ok!\n",
      "statics: Ok!\n",
      "assistments12: Ok!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset = \"statics\"\n",
    "\n",
    "def check_q_all_one(dataset):\n",
    "  dir_path = f\"./data/real/{dataset}\"\n",
    "  df = pd.read_csv(os.path.join(dir_path, \"preprocessed_data.csv\"), sep=\"\\t\")\n",
    "  df = df[[\"user_id\", \"item_id\", \"timestamp\", \"correct\", \"skill_id\"]]\n",
    "  Q_mat = load_npz(os.path.join(dir_path, 'q_mat.npz')).toarray()\n",
    "\n",
    "  if any([sum(q) != 1 for q in Q_mat]):\n",
    "    print(f'{dataset}: There is != 1 - count={sum([1 for q in Q_mat if sum(q) != 1])}')\n",
    "  else:\n",
    "    print(f'{dataset}: Ok!')\n",
    "\n",
    "# datasets = [f for f in os.listdir('./data/real')]\n",
    "datasets = ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics', 'assistments12']\n",
    "for d in datasets:\n",
    "  check_q_all_one(d)\n",
    "\n",
    "# check_q_all_one('algebra05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import encode_fast as ef\n",
    "# import encode as ec\n",
    "from scipy import sparse\n",
    "import os, time\n",
    "\n",
    "reload(ef)\n",
    "\n",
    "dataset = \"algebra05\"\n",
    "\n",
    "dir_path = f\"./data/real/{dataset}\"\n",
    "df = pd.read_csv(os.path.join(dir_path, \"preprocessed_data.csv\"), sep=\"\\t\")\n",
    "df = df[[\"user_id\", \"item_id\", \"timestamp\", \"correct\", \"skill_id\"]]\n",
    "Q_mat = sparse.load_npz(os.path.join(dir_path, 'q_mat.npz')).toarray()\n",
    "\n",
    "# Transform q-matrix into dictionary for fast lookup\n",
    "num_items, num_skills = Q_mat.shape\n",
    "Q_mat_dict = {i: set() for i in range(num_items)}\n",
    "for i, j in np.argwhere(Q_mat == 1):\n",
    "    Q_mat_dict[i].add(j)\n",
    "\n",
    "active_features = ['i', 's', 'ic', 'sc', 'tc', 'w', 'a']\n",
    "print('start ...')\n",
    "start = time.time()\n",
    "X = ef.df_to_sparse(df, Q_mat, active_features)\n",
    "print(X.shape)\n",
    "print('----')\n",
    "print(X[-3,5:])\n",
    "end = time.time()\n",
    "print('Timespent: ', (end-start), 's')\n",
    "\n",
    "# 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606983, 173458)\n",
      "(606983, 173458)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_fp = './data/real/algebra05/X-isicsctcwa.npz'\n",
    "orig = csr_matrix(load_npz(npz_fp))\n",
    "# orig = orig[:, 5:]\n",
    "print(X.shape)\n",
    "print(orig.shape)\n",
    "\n",
    "np.array_equal(X.data, orig.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algebra05\n",
      "1    513578\n",
      "0     93405\n",
      "Name: correct, dtype: int64\n",
      "1    458453\n",
      "0    148530\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "assistments09\n",
      "1    219344\n",
      "0     58992\n",
      "Name: correct, dtype: int64\n",
      "1    183303\n",
      "0     95033\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "assistments15\n",
      "1    526963\n",
      "0    129191\n",
      "Name: correct, dtype: int64\n",
      "1    479165\n",
      "0    176989\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "assistments17\n",
      "1    504531\n",
      "0    430107\n",
      "Name: correct, dtype: int64\n",
      "0    584977\n",
      "1    349661\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "bridge_algebra06\n",
      "1    1610453\n",
      "0     206940\n",
      "Name: correct, dtype: int64\n",
      "1    1512344\n",
      "0     305049\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "spanish\n",
      "1    498361\n",
      "0     80365\n",
      "Name: correct, dtype: int64\n",
      "1    447372\n",
      "0    131354\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "statics\n",
      "1    159475\n",
      "0     29822\n",
      "Name: correct, dtype: int64\n",
      "1    144883\n",
      "0     44414\n",
      "Name: correct, dtype: int64\n",
      "=====\n",
      "assistments12\n",
      "1    2115594\n",
      "0     566617\n",
      "Name: correct, dtype: int64\n",
      "1    1866608\n",
      "0     815603\n",
      "Name: correct, dtype: int64\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "dataset = \"bridge_algebra06\"\n",
    "datasets = ['algebra05', 'assistments09', 'assistments15', 'assistments17', 'bridge_algebra06', 'spanish', 'statics', 'assistments12']\n",
    "# datasets = ['statics']\n",
    "\n",
    "\n",
    "for d in datasets:\n",
    "  print(d)\n",
    "  dir_path = f\"./simulation/simulated-data-pfa/{d}/{d}.csv\"\n",
    "  df1 = pd.read_csv(dir_path, sep=\"\\t\")\n",
    "\n",
    "  dir_path = f\"./data/real/{d}\"\n",
    "  df2 = pd.read_csv(os.path.join(dir_path, \"preprocessed_data.csv\"), sep=\"\\t\")\n",
    "\n",
    "  # print(sorted(df.item_id.unique()))\n",
    "  # df[df.item_id == 0]\n",
    "  print(df1.correct.value_counts())\n",
    "  print(df2.correct.value_counts())\n",
    "  print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "DATA_DIR = \"/Volumes/NREXT/proj/research/data\"\n",
    "ORIG_SIM_DIR = \"/Volumes/NREXT/proj/research/danny-edm/simulation\"\n",
    "\n",
    "for d in datasets:\n",
    "  # src_file = f\"{DATA_DIR}/real/{d}/simulated-bestlr.csv\"\n",
    "  src_file = f\"{ORIG_SIM_DIR}/simulated-data-pfa/{d}/{d}.csv\"\n",
    "  dest_file = f\"{DATA_DIR}/simulation/{d}/pfa/simulated-pfa.csv\"\n",
    "\n",
    "  shutil.copyfile(src_file, dest_file)\n",
    "  # os.rename(src_file, dest_file)\n",
    "  # for s in ['bestlr', 'pfa', 'dkt']:\n",
    "  #   os.makedirs(f\"{target_dir}/{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
